{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "540f0b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0378, -0.0696, -0.0798,  ...,  0.0482,  0.0729,  0.0185],\n",
      "        [ 0.0557, -0.0059,  0.0873,  ..., -0.0572,  0.0304, -0.0263],\n",
      "        [-0.0543, -0.0431, -0.0243,  ..., -0.0414, -0.0536,  0.0338],\n",
      "        ...,\n",
      "        [ 0.0972,  0.0026,  0.0098,  ..., -0.0662,  0.0016, -0.0164],\n",
      "        [-0.0277,  0.0203,  0.0720,  ...,  0.0602, -0.0169,  0.0816],\n",
      "        [-0.0357, -0.0098, -0.0157,  ...,  0.0080, -0.0244,  0.0466]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 6.2517e-02, -1.6021e-02,  7.6172e-02,  8.6833e-02, -7.9680e-02,\n",
      "        -4.5910e-03, -1.1876e-02, -9.5774e-03, -4.5640e-02, -7.6652e-02,\n",
      "         8.8484e-02,  3.6813e-02,  3.3939e-02,  3.4076e-03, -6.6057e-02,\n",
      "         5.9923e-02, -8.5061e-03,  3.2037e-02,  3.1046e-02, -1.4407e-02,\n",
      "        -1.2797e-02, -2.5189e-02, -7.6961e-02, -4.9313e-02, -9.6083e-03,\n",
      "         9.4143e-02,  4.7632e-02,  7.3291e-02, -8.5419e-02,  5.1842e-02,\n",
      "        -7.9833e-02,  7.4081e-02,  9.7824e-02, -3.5624e-02,  2.4199e-02,\n",
      "        -3.9599e-02,  5.8522e-02,  3.9318e-02,  5.6008e-02,  5.1211e-02,\n",
      "         9.0059e-02, -5.9798e-05, -7.5127e-02, -8.0536e-02, -9.9525e-03,\n",
      "         7.7893e-02,  8.6055e-02, -3.1883e-02, -2.0867e-02, -1.7879e-02,\n",
      "         5.4164e-02,  2.6672e-02, -1.5037e-04, -7.5106e-02,  7.8903e-02,\n",
      "        -7.1565e-02, -9.3492e-03,  3.3952e-02,  8.3269e-04, -7.6953e-02,\n",
      "         4.5462e-02, -8.3140e-02,  2.4300e-02,  2.5366e-02, -4.5636e-02,\n",
      "        -7.8872e-03,  6.5496e-02, -6.3301e-02, -1.4402e-02, -4.8565e-02,\n",
      "         6.5677e-02,  3.9124e-02, -8.9386e-02,  1.2953e-02,  4.1752e-02,\n",
      "         6.5087e-02,  2.4625e-02, -5.2144e-02,  4.5925e-02,  7.4906e-02,\n",
      "         1.4164e-02,  3.1686e-03,  6.6465e-03, -3.3475e-02,  4.4207e-02,\n",
      "        -5.9910e-02, -9.0181e-03, -5.0870e-03, -4.0700e-02,  2.0349e-02,\n",
      "        -3.1499e-02, -8.9579e-02,  3.5228e-02, -7.1128e-02, -9.5809e-02,\n",
      "         9.3377e-02,  8.0237e-02, -5.5582e-02, -5.6993e-02, -1.4764e-02,\n",
      "         4.1268e-02, -9.2835e-03, -6.0579e-02, -2.1751e-02,  2.3972e-02,\n",
      "         1.0689e-02, -2.6731e-04,  6.0442e-02,  8.9580e-02, -1.0665e-04,\n",
      "         8.8629e-02, -7.5461e-02,  6.7597e-02, -4.1105e-02, -9.8783e-02,\n",
      "        -2.3181e-02,  9.0816e-02,  6.2795e-02, -7.2311e-02,  4.9615e-02,\n",
      "        -9.4214e-02,  3.2615e-02,  9.3820e-02, -9.3765e-02, -7.9775e-02,\n",
      "         7.8797e-02,  7.0877e-02, -7.5435e-02,  3.1599e-02, -6.5234e-02,\n",
      "        -8.2743e-02,  9.1341e-03, -7.2590e-02, -5.6405e-02,  2.3458e-02,\n",
      "         7.2556e-03,  8.9700e-02,  8.9078e-02,  2.6975e-03, -1.1699e-02,\n",
      "        -5.5756e-02,  3.2535e-03,  5.5382e-02,  8.4021e-03, -8.5671e-02,\n",
      "        -7.0177e-02, -7.5972e-02, -1.8979e-02, -9.9646e-02, -4.4181e-03,\n",
      "         7.4904e-02, -3.4068e-02, -6.0434e-02, -4.4688e-02, -6.5720e-02,\n",
      "        -5.2996e-04,  4.9329e-02, -3.0689e-02, -3.4801e-02,  2.6288e-02,\n",
      "        -8.9488e-02,  4.2419e-02, -6.5577e-02, -5.6346e-02, -1.3740e-02,\n",
      "        -1.3046e-02, -4.1776e-02,  6.9827e-02, -2.5918e-02, -1.4630e-03,\n",
      "         4.7539e-02,  6.7590e-02, -7.8105e-02,  4.0942e-02, -3.9287e-02,\n",
      "         9.7750e-02,  1.1446e-02,  2.2789e-02, -9.7579e-02, -3.8131e-02,\n",
      "         6.1175e-02,  1.5219e-02, -7.9565e-02,  6.4845e-02, -1.6532e-03,\n",
      "         9.3942e-02, -4.4149e-02, -2.6997e-03,  1.9224e-02, -1.8279e-02,\n",
      "        -8.6419e-02,  7.8261e-05,  2.9509e-02, -7.0464e-02,  7.4843e-02,\n",
      "        -4.5626e-02, -7.9554e-02,  4.3120e-02,  7.6599e-02, -4.7613e-02],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0351, -0.0321,  0.0519,  ...,  0.0672, -0.0151, -0.0524],\n",
      "        [-0.0370, -0.0371,  0.0595,  ..., -0.0567, -0.0190, -0.0530],\n",
      "        [-0.0554,  0.0540,  0.0327,  ..., -0.0400,  0.0236,  0.0421],\n",
      "        ...,\n",
      "        [ 0.0704,  0.0081, -0.0508,  ..., -0.0061, -0.0048, -0.0656],\n",
      "        [ 0.0006,  0.0308,  0.0090,  ..., -0.0562,  0.0280,  0.0477],\n",
      "        [ 0.0704,  0.0115,  0.0056,  ..., -0.0300,  0.0267,  0.0498]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0038, -0.0141,  0.0534, -0.0559, -0.0293, -0.0320,  0.0433, -0.0698,\n",
      "         0.0065,  0.0314], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0351, -0.0321,  0.0519,  ...,  0.0672, -0.0151, -0.0524],\n",
      "        [-0.0370, -0.0371,  0.0595,  ..., -0.0567, -0.0190, -0.0530],\n",
      "        [-0.0554,  0.0540,  0.0327,  ..., -0.0400,  0.0236,  0.0421],\n",
      "        ...,\n",
      "        [ 0.0704,  0.0081, -0.0508,  ..., -0.0061, -0.0048, -0.0656],\n",
      "        [ 0.0006,  0.0308,  0.0090,  ..., -0.0562,  0.0280,  0.0477],\n",
      "        [ 0.0704,  0.0115,  0.0056,  ..., -0.0300,  0.0267,  0.0498]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0038, -0.0141,  0.0534, -0.0559, -0.0293, -0.0320,  0.0433, -0.0698,\n",
      "         0.0065,  0.0314], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67fc84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.2974, 0.2991, 0.1098]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[-0.4483,  0.4878, -0.3032],\n",
      "        [-0.5177, -0.4403, -0.5045]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1047, 0.4450], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[0.0840, 0.1039]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87450057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837073d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
